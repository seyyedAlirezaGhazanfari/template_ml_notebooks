{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da5ef68b",
   "metadata": {},
   "source": [
    "<font face=\"XB Zar\" size=5><div dir=rtl align=center>\n",
    "<font face=\"XB Zar\" size=5>\n",
    "به نام خدا\n",
    "</font>\n",
    "<br> <br>\n",
    "<font size=3>\n",
    "دانشگاه صنعتی شریف - دانشکده مهندسی کامپیوتر\n",
    "</font>\n",
    "<br> <br>\n",
    "<font color=blue size=5>\n",
    "مقدمه‌ای بر یادگیری ماشین\n",
    "</font>\n",
    "\n",
    "<hr/> <br>\n",
    "<font color=red size=6>\n",
    "فصل سوم: یادگیری، ارزیابی و تنظیم‎کردن مدل‎ها \n",
    "<br>\n",
    "</font>\n",
    "<br>\n",
    "نویسندگان: <br> \n",
    "<br>علیرضا گرگوری مطلق، پیمان ناصری، علیرضا حیدری\n",
    "<hr>\n",
    "</div></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa2644e",
   "metadata": {},
   "source": [
    "<div dir=rtl align=right>\n",
    "<div id=\"table-of-contents\">\n",
    "  <h1>فصل سوم: یادگیري، ارزیابی و تنظیم کردن مدلها</h1>\n",
    "    \n",
    "  <ul>\n",
    "    <li><a href=\"#section-intro\">مقدمه</a>\n",
    "    <li><a href=\"#section-1\">بخش اول</a>\n",
    "      <ul>\n",
    "        <li><a href=\"#1.1 hyperplane\"> 1.1 ابر صفحه</a></li>\n",
    "        <li><a href=\"#1.2 Margin\"> 2.1 حاشیه</a></li>\n",
    "        <li><a href=\"#Maximal Margin Classifier\"> 3.1 طبقه‌بندی بیشینه‌نمای حاشیه</a></li>\n",
    "  </ul>\n",
    "        <li><a href=\"#section-2\">بخش دوم</a>\n",
    "   <ul>\n",
    "        <li><a href=\"#Gradient Descent\">1.2 نزول گرادیان</a></li>\n",
    "        <li><a href=\"#Gradient Descent for Maximal Margin Classifier\"> 2.2 نزول گرادیان برای طبقه بندی بیشینه نمای حاشیه </a></li>\n",
    "  </ul>\n",
    "    <li><a href=\"#section-3\">بخش سوم</a></li>\n",
    "   <ul>\n",
    "       <li><a href=\"#Introducing the Scikit-Learn library\">Scikit-Learn  3.1 معرفی کتابخانه </a></li>\n",
    "   </ul>  \n",
    "       <li><a href=\"#section-4\">بخش چهارم</a>\n",
    "      <ul>\n",
    "        <li><a href=\"#SupportVectorClassifier\">1.4 طبقه‌بندی بردار پشتیبانی </a></li>\n",
    "        <li><a href=\"#svc_first_limit\">2.4محدودیت اول: وابستگی به نقاط مرزی </a></li>\n",
    "        <li><a href=\"#solution1: Soft Margin Classifier\">  3.4راه حل اول: طبقه بندی نرم حاشیه</a></li>\n",
    "        <li><a href=\"#The second limitation: lack of linear separability of the data\">4.4محدودیت دوم: عدم تفکیک‌پذیری خطی داده‌ها</a>           </li>\n",
    "        <li><a href=\"#Second solution: Using Kernel\">5.4راه حل دوم: استفاده از کرنل </a></li>\n",
    "  </ul>\n",
    "        <li><a href=\"#section-5\">بخش پنجم</a>\n",
    "      <ul>\n",
    "        <li><a href=\"#Polynomial Kernel\"> 1.5 کرنل چندجمله‌ای </a></li>\n",
    "        <li><a href=\"#Radial Basis Function\"> 2.5 کرنل RBF</a></li>\n",
    "  </ul>\n",
    "          <li><a href=\"#section-6\">بخش ششم</a>\n",
    "      <ul>\n",
    "        <li><a href=\"#Polynomial Kernel\"> 1.6 چندجمله‌ای </a></li>\n",
    "        <li><a href=\"#Radial Basis Function\"> 2.6 کرنل RBF</a></li>\n",
    "  </ul>\n",
    "        <li><a href=\"#section-7\">بخش هفتم</a>\n",
    "      <ul>\n",
    "         <li><a href=\"#svm decomposition\">1.7 پیچیدگی طبقه بندی بردار پشتیبان</a></li>\n",
    "  </ul>\n",
    "        <li><a href=\"#section-8\">بخش هشتم</a>\n",
    "      <ul>\n",
    "         <li><a href=\"#Multi-Class SVC\"> 1.8 طبقه‌بند بردار پشتیبان چندکلاسه</a></li>\n",
    "         <li><a href=\"#One-vs-Rest (One-vs-All)\">One-vs-Rest (One-vs-All) 2.8</a></li>\n",
    "         <li><a href=\"#One-vs-One\">One-vs-One (One-vs-All) 3.8</a></li>\n",
    "  </ul>\n",
    "            <li><a href=\"#section-9\">بخش نهم</a>\n",
    "      <ul>\n",
    "         <li><a href=\"#Support Vector Regression\"> 1.9 رگرسیون بردار پشتیبان</a></li>\n",
    "   </ul> \n",
    "             <li><a href=\"#section-10\">بخش دهم</a>\n",
    "      <ul>\n",
    "         <li><a href=\"#Hyperparameters setting and model selection\"> 1.10 تنظیم هایپرپارامتر‌ها و انتخاب مدل</a></li>\n",
    "         <li><a href=\"#Evaluation criteria of models\"> 2.10 معیار های مختلف ارزیابی مدل ها در مسائل دسته‌بندی و رگرسیون</a></li>\n",
    "         <li><a href=\"#Calculate accuracy\"> 3.10 محاسبه دقت</a></li>\n",
    "         <li><a href=\"#Confusion Matrix\"> 4.10 ماتریس سردرگمی</a></li>\n",
    "         <li><a href=\"#Precision/Recall tradeoff\"> 5.10 معاوضه دقت و یادآوری</a></li>\n",
    "         <li><a href=\"#ROC Curve\"> 6.10 منحنی ROC</a></li>\n",
    "         <li><a href=\"#AUC\"> 7.10 مساحت زیر منحنی AUC</a></li>\n",
    "           \n",
    "</div>\n",
    "\n",
    "<div id=\"section-1\">\n",
    "  <h2>Section 1</h2>\n",
    "  <div id=\"section-1-subsection-1\">\n",
    "    <h3>Subsection 1.1</h3>\n",
    "    <p>Content of subsection 1.1 goes here.</p>\n",
    "  </div>\n",
    "  <div id=\"section-1-subsection-2\">\n",
    "    <h3>Subsection 1.2</h3>\n",
    "    <p>Content of subsection 1.2 goes here.</p>\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "<div id=\"section-2\">\n",
    "  <h2>Section 2</h2>\n",
    "  <p>Content of section 2 goes here.</p>\n",
    "</div>\n",
    "\n",
    "<div id=\"section-3\">\n",
    "  <h2>Section 3</h2>\n",
    "  <div id=\"section-3-subsection-1\">\n",
    "    <h3>Subsection 3.1</h3>\n",
    "    <p>Content of subsection 3.1 goes here.</p>\n",
    "  </div>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee51e14-31fa-4b7d-9cd4-7fb83c5029ac",
   "metadata": {},
   "source": [
    "<div dir=rtl id=\"section-intro\">\n",
    "    <h2>\n",
    "        <font color=\"red\" size=5>مقدمه</font>\n",
    "    </h2>\n",
    "    <hr>\n",
    "    <div dir=rtl>\n",
    "        <font face=\"XB Zar\" size=4>\n",
    "            در این فصل قصد داریم که به معرفی مفاهیم پایه‌ای و البته مهمی در یادگیری ماشین بپردازیم. تمرکز ما برای معرفی مفاهیم مرتبط،\n",
    "            مدل <b>ماشین‌های بردار پشتیبان</b>\n",
    "            (Support Vector Machines)\n",
    "می باشد؛ در ابتدا به پیاده‌سازی مدل ساده‌شده‌ای از SVM پرداخته و سپس به معرفی کتابخانه\n",
    "Scikit-Learn\n",
    "که یکی از مهمترین و قدرتمندترین کتابخانه‌های موجود در زمینه یادگیری ماشین است میپردازیم.\n",
    "در ادامه با استفاده از ماژول‌های این کتابخانه مدل‌های پیچیده‌تری را پیاده‌سازی خواهیم کرد و نحوه ارزیابی و انتخاب مدل‌های مناسب را بر اساس معیارهای مدنظرمان فرا خواهیم گرفت.\n",
    "<br> <br>\n",
    "پیش از شروع بحث بهتر است به معرفی ابرصفحه (Hyperplane) و نیز حاشیه (Margin) بپردازیم.\n",
    "<br><b> (در سراسر این فصل فرض می‌شود که $N$ تعداد نمونه‌های ما و $p$ تعداد ویژگی‌های هر نمونه می‌باشد.) \n",
    "        </font>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182b095e-2a69-456d-beb9-87ffa36caeec",
   "metadata": {},
   "source": [
    "<div dir=rtl id=\"section-4\">\n",
    "    <h1>\n",
    "        <font color=\"red\" size=5>بخش چهارم</font> \n",
    "    </h1>\n",
    "    <hr>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20471565-92ff-46f5-9a11-e47c31a00896",
   "metadata": {},
   "source": [
    "<div dir=rtl id=\"SupportVectorClassifier\">\n",
    "    <h2>\n",
    "        <font color=\"orange\" size=5>طبقه‌بند بردار پشتیبان (Support Vector Classifier)</font> \n",
    "    </h2>\n",
    "    <hr>\n",
    "    <font face=\"XB Zar\" size=4>\n",
    "    همانطور که می‌توانید حدس بزنید و در کلاس نیز اشاره شده است، طبقه‌بند بیشینه‌نمای حاشیه (Maximal Margin Classifier) فقط در شرایطی عملکرد صحیحی دارد که\n",
    "    داده‌های دو کلاس به طور خطی تفکیک‌پذیر باشند. همچنین مرز این مدل توسط نمونه‌هایی مشخص می‌شود که بر روی حاشیه قرار میگیرند؛ در واقع در صورتی که فقط یکی از نمونه‌های آموزشی نزدیک به مرز مقداری تغییر اندازه داشته باشد، مرز تصمیم‌گیری به طور کامل تغییر میکند! \n",
    "    ذکر این نکته حائز اهمیت است که داده‌های ما در واقعیت در اکثر موارد مقداری Noise دارند و بنابراین مشکل بالا می‌تواند اثر نامطلوبی روی مرز تصمیم‌گیری ما داشته باشد. بنابراین این مدل به شدت قابلیت بیش‌برازش شدن (Overfitting) دارند.\n",
    "<br>\n",
    "<br> در ادامه، برای حالت گفته‌شده، مدل Maximal Margin Classifier را با استفاده از Scikit-learn امتحان میکنیم:\n",
    "    </font>\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c17fe7-2243-4d21-b220-e68b1a04b697",
   "metadata": {},
   "source": [
    "<div dir=rtl id=\"svc_first_limit\">\n",
    "    <h2>\n",
    "        <font color=\"orange\" size=5>محدودیت اول: وابستگی به نقاط مرزی  </font> \n",
    "    </h2>\n",
    "    <hr>\n",
    "    <font face=\"XB Zar\" size=4> \n",
    "خط بهینه در این حالت به نقاط مرزی وابستگی زیادی دارد؛ بنابرین تغییر کوچکی در هر یک از آن‌ها(همچون وجود نویز یا دلایل دیگر) معادله خط جدا کننده را تحت تاثیر شدید قرار می‌دهد؛ بنابراین، این مدل به شدت قابلیت بیش‌برازش دارد.\n",
    "<br>در ادامه بر روی دیتاست اولیه که قابلیت جدایی‌پذیری خطی را دارد، مدل خود را برازش می‌کنیم؛ سپس یک نمونه‌ی نویزی به هر کلاس اضافه میکنیم و اثر آن‌ها را بر روی مرز تصمیم‌گیری مشاهده می‌کنیم:\n",
    "</font>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a75e85-3ff3-4c54-9a26-16c7be064092",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
